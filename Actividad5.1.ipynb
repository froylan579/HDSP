{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6157b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "#for dirname, _, filenames in os.walk(r'C:\\Users\\Calidad\\DATA'):\n",
    "    #for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "893e5370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2df2179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_path= r'C:\\Users\\Calidad\\DATA'\n",
    "data_generator = tf.keras.preprocessing.image.ImageDataGenerator (\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d66933c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 76 images belonging to 2 classes.\n",
      "Found 18 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_data=data_generator.flow_from_directory(\n",
    "    image_dir_path,\n",
    "    seed=42,\n",
    "    target_size=(200,200),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "Validation_data=data_generator.flow_from_directory(\n",
    "    image_dir_path,\n",
    "    seed=42,\n",
    "    target_size=(200,200),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0514cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(200,200,3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2,activation='softmax')\n",
    "])\n",
    "seq_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03724bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Calidad\\AppData\\Local\\Temp\\ipykernel_15700\\1643162465.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  trained_seq_model=seq_model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.4741 - accuracy: 0.6447 - val_loss: 0.4597 - val_accuracy: 0.7778\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.4741 - accuracy: 0.8553 - val_loss: 0.4900 - val_accuracy: 0.7778\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 5s 1s/step - loss: 0.4804 - accuracy: 0.7895 - val_loss: 0.3922 - val_accuracy: 0.8333\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 5s 1s/step - loss: 0.3634 - accuracy: 0.8289 - val_loss: 0.2329 - val_accuracy: 0.9444\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.4102 - accuracy: 0.8289 - val_loss: 0.2899 - val_accuracy: 0.8889\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 5s 1s/step - loss: 0.3648 - accuracy: 0.8158 - val_loss: 0.1836 - val_accuracy: 0.8889\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 5s 1s/step - loss: 0.2631 - accuracy: 0.9211 - val_loss: 0.3070 - val_accuracy: 0.8333\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 5s 1s/step - loss: 0.1560 - accuracy: 0.9868 - val_loss: 0.0928 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 5s 1s/step - loss: 0.1249 - accuracy: 0.9605 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 5s 1s/step - loss: 0.0606 - accuracy: 0.9868 - val_loss: 0.1426 - val_accuracy: 0.9444\n"
     ]
    }
   ],
   "source": [
    "trained_seq_model=seq_model.fit_generator(\n",
    "    training_data,\n",
    "    epochs=10,\n",
    "    validation_data=Validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f056b654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: covid_classifier\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: covid_classifier\\assets\n"
     ]
    }
   ],
   "source": [
    "seq_model.save('covid_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5d218fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Negativo a COVID\n"
     ]
    }
   ],
   "source": [
    "test_image=tf.keras.preprocessing.image.load_img(r'C:\\Users\\Calidad\\DATA\\NORMAL\\IM-0115-0001.jpeg',target_size=(200,200,3))\n",
    "test_image=tf.keras.preprocessing.image.img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "result=seq_model.predict(test_image)\n",
    "if result[0][0]==1:\n",
    "    print('Positivo a COVID')\n",
    "else:\n",
    "    print('Negativo a COVID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45fc908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Positivo a COVID\n"
     ]
    }
   ],
   "source": [
    "test_image=tf.keras.preprocessing.image.load_img(r'C:\\Users\\Calidad\\DATA\\COVID\\ryct.2020200028.fig1a.jpeg',target_size=(200,200,3))\n",
    "test_image=tf.keras.preprocessing.image.img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "result=seq_model.predict(test_image)\n",
    "if result[0][0]==1:\n",
    "    print('Positivo a COVID')\n",
    "else:\n",
    "    print('Negativo a COVID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8966752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f430354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
